======================================================================================
	MONITORAMENTO DE CLUSTERS HADOOP DE ALTO NIVEL COM HDFS E YARN 
			TEORIA E PRATICA COM HDFS
======================================================================================
1. ABRA SEU TERMINAL MOBAXTERM, LIGUE SUA VM E ENTRE COM O USUARIO HADOOP
2. LIGUE O HDFS 
	2.1 cd $HADOOP_HOME/sbin/ && ./start-dfs.sh && cd /home/hadoop/
	2.2 ESSE COMANDO ACIMA PODE SER QUEBRADO EM 3 COMANDOS, MAS DEIXEI ASSIM POR QUESTÃO DE USABILIDADE
	2.3 NESSES COMANDOS STARTAMOS TODOS OS NODE 
3. LIGUE O YARN
	3.1 cd $HADOOP_HOME/sbin/ && ./start-yarn.sh && cd /home/hadoop/
4. COM ISSO, VOCE JA PODE VER OS SERVIÇOS FUNCIONANDO, PODENDO ABRIR NO SEU BROWSER DA MAQUINA MAE
	4.1 http://ipdamaquinaVM:8088
5. NA SUA VM, CRIE UM ARQUIVO EM UM OUTRO USUARIO
	5.1 NO MEU CASO, CRIEI NO MEU USUARIO ANTONIO, UMA PASTA DOWNLOADS E DENTRO DELA COLOQUEI UM ARQUIVO CHAMADO texto.txt
	5.2 NESSE ARQUIVO EU COLOQUEI OS NUMEROS DE 1 A 20
6. VAMOS VER O QUE TEM NA PASTA DE DIRETORIO HDFS
	5.1 hdfs dfs -ls -h /
7. VOCE VAI VER QUE O DIRETORIO HDFS ESTÁ VAZIO, ENTÃO VAMOS CRIAR UMA PASTA CHAMADA TEMP
	7.1 hdfs dfs -mkdir /temp
8. AGORA VOCE COLOCA O SEU ARQUIVO DO SEU DIRETORIO EM OUTRA PASTA DENTRO DA PASTA TMP
	8.1 hdfs dfs -put /home/antonio/downloads/texto.txt /temp/
9. AGORA VOCE TRAZ ESSE ARQUIVO PARA A PASTA DO SEU USUARIO HADOOP, ESSA PASTA ESTÁ FORA DO HDFS
	9.1 hdfs dfs -get /temp/texto.txt
	9.2 ll -> VOCE VAI VER QUE ESSA PASTA NAO E DO HADOOP, MAS DO SEU USUARIO, E LA ESTA O ARQUIVO QUE ESTAVA DENTRO DO HDFS HADOOP
10. A DIFERENÇA ENTRE O LL E O COMANDO HDFS, É QUE SÃO SISTEMAS DE ARQUIVOS DIFERENTES
11. LER O ARQUIVO DE TEXTO DENTRO DO HDFS
	11.1 hdfs dfs -cat /temp/texto.txt | head -10
12. CRIE UM DIRETORIO
	12.1 hdfs dfs -mkdir /temp/delete
	12.2 hdfs dfs -ls /temp
13. AGORA COPIE O ARQUIVO DE TEXTO PARA A NOVA PASTA
	13.1 hdfs dfs -cp /temp/texto.txt /temp/delete
14. CRIAR UM ARQUIVO VAZIO
	14.1 hdfs dfs -touchz /temp/delete/arquivoVazio
15. DELETE A PASTA CRIADA
	15.1 hdfs dfs -rm -R /temp/delete
16. LISTAR A PASTA TEMP
	16.1 hdfs dfs -du /temp
17. VENDO ALGUMAS INFORMAÇÕES USANDO FSCK
	17.1 hdfs fsck /temp -files -blocks
	17.2 AQUI ELE MOSTRA UMA DIFERENÇA PARA O DA AULA, NA AULA ELE USA UM PSEUDO CLUSTER COM 3 NOS
NO NOSSO CASO, CONFIGUREI APENAS 1 NÓ, ENTÃO ELE FICA DIFERENTE, MAS AS SAIDAS SÃO AS MESMA


======================================================================================
	MONITORAMENTO DE CLUSTERS HADOOP DE ALTO NIVEL COM HDFS E YARN 
			TEORIA E PRATICA COM YARN
======================================================================================
1. ABRA SEU TERMINAL MOBAXTERM OU UMA NOVA ABA E ENTRE COM O USUARIO HADOOP
	1.1 OBS: SE VOCE FECHOU A VM ESTÁ ABRINDO DE NOVO, USE OS COMANDOS DE ESTARTAR OS SERVIÇOS YARN E HDFS 
COM O USUARIO HADOOP
	1.2 SERVIÇOS START HDFS: cd $HADOOP_HOME/sbin/ && ./start-dfs.sh && cd /home/hadoop/
	1.3 SERVIÇOS START YARN: cd $HADOOP_HOME/sbin/ && ./start-yarn.sh && cd /home/hadoop/
2. PARA RODAR UM JOB NO YARN USAREMOS O ARQUIVO DE EXEMPLO DO MANUAL DO HADOOP
3. ANTES, VAMOS ESTARTAR O HISTORY SERVER NA ABA DO USUARIO HADOOP
	3.1 HADOOP_HOME/bin/mapred --daemon start historyserver && cd /home/hadoop/
4. ABRA NO SEU NAVEGADOR A PAGINA DOS JOBS
	4.1 http://ipdavm:19888/jobhistory
5. PARA RODAR ESSE JOB EM ESPECIFICO VOCÊ PRECISA FAZER ALGUMAS CONFIGURAÇÕES NO SEU HDFS
	5.1 PRIMEIRO CRIA UMA PASTA USER, DEPOIS UMA PASTA HADOOP E DEPOIS UMA PASTA INPUT
		5.1.1 hdfs dfs -mkdir /user && hdfs dfs -mkdir /user/hadoor && hdfs dfs -mkdir /user/hadoor/input/
	5.2 A PASTA INPUT DEVE RECEBER UM ARQUIVO QUE VAI SER RODADO, VOCE PODE COLOCAR QUALQUER ARQUIVO DE TEXTO OU XML LA,
NO MEU CASO EU SEGUI O EXEMPLO DA DOCUMENTAÇÃO E COLOQUEI ARQUIVOS XML DA PASTA HADOOP
		5.2.1 hdfs dfs -put /usr/local/hadoop/etc/hadoop/*.xml  /user/hadoop/input
6. O JAR QUE VAI SER RODADO, É BASEADO NO MAPREDUCE, ELE VAI PEGAR OS ARQUIVOS DESSA PASTA INPUT E VAI FAZER UMA REDUÇÃO NELES
7. PARA EXECUTAR O JAR, TEM QUE IR ATÉ A PASTA DELE
	7.1 NO MEU CASO ESSA APLICAÇÃO ESTÁ EM:/usr/local/hadoop/share/hadoop/mapreduce
	7.2 USE O COMANDO:cd /usr/local/hadoop/share/hadoop/mapreduce/
	7.3 CASO VOCE TENHA FEITO A CONFIGURAÇÃO DO SEU AMBIENTE DE OUTRA FORMA, ESSE ARQUIVO ESTÁ PRESENTE EM $JAVA_HOME/share/hadoop/mapreduce
8. APOS ESTAR DENTRO DESSA PASTA, USE O COMANDO YARN JAR PARA EXECUTAR O SEU JAR
	8.1  yarn jar hadoop-mapreduce-examples-3.2.2.jar grep input output 'dfs[a-z.]+'grep input output 'dfs[a-z.]+'
	8.2 VAMOS ENTENDER O QUE ACONTECEU:
		8.2.1 yarn jar hadoop-mapreduce-examples-3.2.2.jar -> NESSA PARTE ELE EXECUTA O JAR EXEMPLO
		8.2.2 grep input -> NESSA PARTE ELE PEGA OS ARQUIVOS DE INPUT
		8.2.3 output 'dfs[a-z.]+' -> NESSA PARTE ELE CONSTROI UM OUTPUT COM A REDUÇÃO 
9. PODEMOS VERIFICAR O OUTPUT QUE TIVEMOS
	9.1 hdfs dfs -ls -h /user/hadoop/output
10. PODEMOS VERIFICAR ALGUMAS COISAS DO JOB NO NAVEGADOR
	10.1 http://ipdaVM:8088/cluster
11. OBS: NA PARTE DOS LOGS ACONTECEU ALGO ESTRANHO, OS LOGS ESTÃO DISPONIVEIS NO SITE
MAS NAO CONSIGO ACESSAR ELES PELO yarn logs O QUE ME CAUSA DUVIDA, MAS PROVAVELMENTE SEJA
ALGUM ARQUIVO DE CONFIGURAÇÃO DO mapred-site.xml O QUE NAO TENHO CERTEZA