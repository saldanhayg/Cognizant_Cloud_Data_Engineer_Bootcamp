======================================================================================
			CONFIGURANDO O AMBIENTE HADOOP
======================================================================================
1. PRIMEIRO VAMOS CRIAR UMA VARIAVEL DE AMBIENTE JAVA
	1.1 PRIMEIRO VEJA EM QUAL PASTA ESTÁ LOCALICADA A JDK
		1.1.1 update-alternatives --config java
		1.1.2 no meu caso está em /usr/lib/jvm/java-11-openjdk-amd64/bin/java
	1.2 AGORA CRIE UM ARQUIVO SH PARA AUTOMATIZAR A TAREFA
		1.2.1 cd /etc/profile.d/
		1.2.2 sudo touch java.sh
		1.2.3 sudo nano java.sh
			1.2.3.1 #/bin/bash
				export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
	1.3 REINICIE SUA MÁQUINA VIRTUAL
	1.4 VERIFIQUE SE SUA VARIAVEL FOI CRIADA
		1.4.1 env | grep JAVA_HOME
2. CRIE UM USUÁRIO HADOOP
	2.1 sudo adduser hadoop
3. ENTRE NO USUÁRIO HADOOP
	3.1 su hadoop
4. GEREDE UMA CHAVE SSH PARA O USUARIO
	4.1 ssh-keygen
5. ADICIONE SUA CHAVE A LISTA DE USUARIOS AUTORIZADOS
	5.1 ssh-copy-id ipDaSuaVM
6. SAIA DO SEU USUÁRIO HADOOP
	6.1 exit
7. CRIE UMA PASTA DE DOWNLOAD NO SEU USUARIO NATIVO
	7.1 mkdir downloads/
	7.2 cd downloads/
8. BAIXE O HADOOP 3.2.2 DENTRO DA PASTA DOWNLOADS
	8.1 sudo wget https://mirror.nbtelecom.com.br/apache/hadoop/common/hadoop-3.2.2/hadoop-3.2.2.tar.gz
9. INSTALE O HADOOP 
	9.1 tar -zxvf hadoop-3.2.2.tar.gz
10. MOVA O HADOOP PARA O USUARIO HADOOP
	10.1 sudo mv hadoop-3.2.2 /usr/local/hadoop
11. ELEVE AS PERMISSÕES PARA O USUARIO HADOOP
	11.1 sudo chown hadoop.hadoop /usr/local/hadoop -R
12. AGORA, CRIE AS VARIAVEIS DE AMBIENTES DO HADOOP
	12.1 cd /etc/profile.d/
	12.2 sudo touch hadoop.sh
	12.3 sudo nano hadoop.sh
		12.3.1 #/bin/bash
			export HADOOP_HOME=/usr/local/hadoop
			export HADOOP_HDFS_HOME=$HADOOP_HOME
			export HADOOP_MAPRED_HOME=$HADOOP_HOME
			export HADOOP_COMMON_HOME=$HADOOP_HOME
			export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
			export YARN_HOME=$HADOOP_HOME
			export PATH="$PATH:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin"
13. AGORA DEFINA A VARIAVEL AMBIENTE JAVA NO HADOOP
	13.1 ALTERE O ARQUIVO hadoop-env.sh
		13.1.1 sudo nano /usr/local/hadoop/etc/hadoop/hadoop-env.sh
		13.1.2 ADICIONE NO FINAL DO ARQUIVO O export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
14. REINICIE A MAQUINA
15. DESLIGUE A VM PARA O PROXIMO PASSO

=======================================================================================
			  2. CONFIGURANDO O HDFS E O YARN
=======================================================================================
1. LIGUE SUA MAQUINA VIRTUAL E LOGUE NELA PELO SEU SSH MOBAXTERM COM O USUARIO NÃO HADOOP
2. A CONFIGURAÇÃO VAI SER A DE UMA PSEUDO DISTRIBUIÇÃO COM YARN SINGLE MODO
3. ENTRE NA PASTA DE CONFIGURAÇÃO HADOOP
	3.1 cd /usr/local/hadoop/etc/hadoop/
4. MODIFIQUE O ARQUIVO core-site.xml
	3.1 nano core-site.xml
	3.2 <?xml version="1.0" encoding="UTF-8"?>
	    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
		<configuration>
		<property>
      			<name>fs.default.name</name>
      			<value>hdfs://localhost:9000</value>
      			<description>The default file system URI</description>
		</property>
		</configuration>
5. CONFIGURE AGORA OS NAME-NODE E OS DATA-NODE
	5.1 ABRA O ARQUIVO hdfs-site.xml
		5.1.1 nano hdfs-site.xml
		5.1.2 <?xml version="1.0" encoding="UTF-8"?>
		      <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
			<configuration>
				<property>
      					<name>dfs.replication</name>
      					<value>1</value>
   				</property>
   				<property>
      					<name>dfs.name.dir</name>
      					<value>file:///hadoop/hdfs/namenode</value>
   				</property>
   				<property>
      					<name>dfs.data.dir</name>
      					<value>file:///hadoop/hdfs/datanode</value>
   				</property>
			</configuration>
6. AGORA VAMOS CONFIGURAR O YARN
7. EDITE O ARQUIVO mapred-site.xm
	7.1 sudo nano /usr/local/hadoop/etc/hadoop/mapred-site.xml
	7.2 <?xml version="1.0"?>
		<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
		<configuration>
		<property>
  		<name>mapreduce.framework.name</name>
  		 <value>yarn</value>
		 </property>
		</configuration>
8. EDITE O ARQUIVO yarn-site.xml
	8.1 sudo nano /usr/local/hadoop/etc/hadoop/yarn-site.xml
	8.2	<?xml version="1.0"?>
		<configuration>
		<property>
  			<name>yarn.nodemanager.aux-services</name>
  			<value>mapreduce_shuffle</value>
		</property>
		<!-- Site specific YARN configuration properties -->
		</configuration>

9. CRIE OS DIRETORIOS NECESSARIOS
	9.1 sudo mkdir -p /hadoop/hdfs/namenode
	9.2 sudo mkdir -p /hadoop/hdfs/datanode
	9.3 sudo chown -R hadoop:hadoop /hadoop
10. COMANDOS PARA FORMATAR O NOME
	10.1 su hadoop
	10.2 cd /usr/local/hadoop/bin
	10.3 ./hdfs namenode -format	
11. NO MEU CASO, HOUVE ALGUNS ERROS ONDE MEU SSH NAO CONSEGUIA ACESSAR O LOCALHOST SEM SENHA,
PARA ISSO, A DOCUMENTAÇÃO DO HADOOP OFERECE A SEGUINTE ALTERNATIVA
	ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
  	cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
  	chmod 0600 ~/.ssh/authorized_keys
12. AGORA VOCE PODE INICIAR O DFS 
	12.1 su hadoop
	12.2 cd $HADOOP_HOME/sbin/
	12.3 ./start-dfs.sh
13. AGORA VAMOS ADICIONAR MUDANÇAS NOS ARQUIVOS yarn-site.xml e mapred-site.xml
	13.1 COMANDOS E ALTERAÇÕES PARA yarn-site.xml
		13.1.1 nano nano /usr/local/hadoop/etc/hadoop/yarn-site.xml
		13.1.2 <configuration>
    			<property>
        			<name>yarn.nodemanager.aux-services</name>
        			<value>mapreduce_shuffle</value>
   			</property>
    			<property>
        			<name>yarn.nodemanager.env-whitelist</name>
        			<value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ,HADOOP_MAPRED_HOME</value>
    			</property>
			</configuration>
	13.2 COMANDOS E ALTERAÇÕES PARA mapred-site.xml
		13.2.1 nano /usr/local/hadoop/etc/hadoop/mapred-site.xml
		13.2.2 <configuration>
    		       <property>
        		<name>mapreduce.framework.name</name>
        		<value>yarn</value>
    			</property>
    			<property>
        		<name>mapreduce.application.classpath</name>
        		<value>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*</value>
    			</property>
			</configuration>
14. POR FIM SETAMOS O YARN
	su hadoop
	cd $HADOOP_HOME/sbin/
	./start-yarn.sh
15. DESLIGUE A MAQUINA
	
=======================================================================================
					REFERENCIAS
=======================================================================================
1. https://techexpert.tips/pt-br/apache-hadoop-pt-br/instalacao-apache-hadoop-no-ubuntu-linux/
2. https://pplware.sapo.pt/tutoriais/apache-hadoop-instalacao-ubuntu/
3. https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html#Pseudo-Distributed_Operation


		